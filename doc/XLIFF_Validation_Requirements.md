Overview

This code represents a validate pipeline that validates XLIFF 2.0 files for the KLMS project.
It is used as a check against producing invalid XLIFF files, and ensures any generated XLIFF 
files are compliant to the requirements. It is very important to note that in these files (due to 
limitations of some of the tools that generate and read these files, and also due to making it 
super-easy to use with visual diff tools like Beyond Compare), everything matters: whitespace, newlines, 
formatting, case, structure. So, when generating a file or doing translation, the spacing, indentions, 
trailing whitespace, newlines, case , etc must match the English master exactly, and any generated 
target must match the source structure and format exactly. So this validation pipeline checks to this
very strict level of compliance.

User Entry Point

This code has no external dependencies and is standalone. It can be run as a program which calls the main() 
method and as arguments accepts one file path or two. If one file, it will run the single XLIFF file validation 
checks, if two files are specificed it will run the file pair validation checks (which include the single file 
checks). ChatGPT should not attempt to use this entry point because its environment does not allow execution 
of python code from a command line. Instead, ChatGPT should use the entry points specified below.

ChatGPT Entry Points

ChatGPT's has access to files at the project level, and their paths are like /mnt/data/klms8-messages(es).xlf 
So ChatGPT should use the validate_xliff_file() or validate_xliff_file_pair() entry points. For generated 
files, they should also be written to /mnt/data before invoking these methods. The array of validation issues 
returned by these methods can be used to render the results in the UI, or be used by ChatGPT to analyze what 
went wrong with it's generation code and try to fix the issues. This validation should be run on any XLIFF file 
generated by ChatGPT before the file is brought to the user's attention for review. This prevents wasting the 
user's time reviewing incorrect results. If ChatGPT generates a file and it fails these checks, it should use 
this validation output to diagnose it's code and resolve it. ChatGPT should continuously fix and validate in 
a cycle until a correct result is produced, or it gives up and needs user assistance in helping to resolve 
what is wrong because it ran of out ideas on how to fix the code to resolve the issues reported by this pipeline.

Validation Issues

Validation issues are reported as a structure that includes:

- Validator name (which validator found the issue, this should be a short name)
- Validator message (a message which indicates exactly what went wrong, not just "problem" or "issue" or "mismatch")
- File name (not full file path, just the name) the issue was detected in
- Line Number the issue was detected on
- Column range (start and end) that identify the start and end column of line that caused the issue
- Unit ID that the line is part of, if the problem happened within the context of a containing unit element
- The actual text of the line that the validation issue was found on

Constructing Validation Issue Objects

Because validation issues have strict requirements on things like knowing line numbers, column ranges, etc any 
third-party tools used (like XML or HTML validators) must be able to report line and column numbers, and configured
propertly to do so. When a third party tool returns issues, the information needed to construct a validation issue 
object must be extracted from the object returned by the third party tool. Thinks like the unit id will need to be
computed based on line number, because the third-party tool will be unaware of XLIFF standard.

Displaying Validation Issues

If they are in ChatGPT chat they should be rendered in a tabular form. When displaying the actual text of the line 
that caused the error, that text should be highlighted in bright yellow. For readability this can be shortened 
by truncating leading or trailing part of the line and replacing it with ellipses, but leaving enough context 
to allow identiciation of which part of the line caused the issue.

If displayed from a command-line, they should be displayed as an ASCII art table with fixed width columns. 
Instead of highlighting the area in yellow that caused the issue, enclose the problem range between >>> and <<<

Validation Pipeline Steps

# XLIFF Single File Validation Pipeline Checks

These checks are checking the consistency of any XLIFF 2.0 file, an English master or a translated language file.
These checks prevent common problems ChatGPT has with generated XLIFF 2.0 files.

CHECK #1: UTF-8 BOM
Check that the file has the a UTF-8 BOM

CHECK #2: XML Declaration
Check that the XML declaration is present and exacty matches: <?xml version="1.0" encoding="UTF-8"?>
Common ChatGPT problems are forgetting to have one, using single quotes, or using lowercase utf-8.

CHECK #4: XML Namespace Prefixes
Check that the file does not contain element namespace prefixes like "ns0:".

CHECK #5: XLIFF Element
Check that the xliff element contains all four attributes, they have the right values, and they are in the correct order:
<xliff xmlns="urn:oasis:names:tc:xliff:document:2.0" version="2.0" srcLang="en" trgLang="XX">
The language code for the trgLang should match that of the language being targeted and also match the language code in the 
filename in parenthesis at the end of the name. Also, validate the language code is a valid language code based on standards
like XLIFF 2.0, ISO, etc.

CHECK #6: XML Validation
Check the file has no issues (no warnings or validation_issues) using an XML validator in the strictest validation mode (all checks enabled).

CHECK #7: XLIFF Schema
Check the XLIFF file against the xliff_core_2.0.xsd.

CHECK #8: Duplicate IDs
Check the XLIFF file for duplicate IDs. file and unit elements must have globally unique IDs.
Within the scope of the unit, data element ids must be unique. As an added constraint, their ID naming pattern includes a 
sequence number after the first underscore that must start at 1 for the first data element and increment by 1 for each 
element without skipping and without duplication.

CHECK #9: Java Placeholder
Ensure Java placeholders (such as {0}, {1}, etc.) are correct between each source and target pair. The count of the number of 
times each placeholder is used should match between source and target, but the ordering doesn't matter since in translation 
they may be rearranged.

CHECK #10: Target Format
Check each target block against its source to ensure the formatting and first tag on each line is the same as the source.
For each unit in the file, make a list of lines of the source block, and a list of lines of the target block,
and then call a utility function to a basic compare of those two lists. The target should have the same number of lines as the source, 
each line of the target should have: the same leading whitespace as the matching source line, the same trailing whitespace as the matching source line, 
and start with the same tag as the source line does.
There are two exceptions: on any line if you detect the starting tags are "<source" and "<target", or "</source" and "</target", 
which will happen when comparing a source block to a target block, consider those equivalent and don't create a validation issue.

CHECK #11: Untranslated Targets
If the trgLang of the file differs from the srcLang, then this file represents a file with translations. Each segment that is 
not in state "initial" should be checked to make sure the target is not empty and is different than the source and that it 
doesn't contain the text from the source. The target may contain XLIFF placeholders (pc and ph tags) so the value's XML DOM will 
have to be walked checking for at least one non-blank text node.

Common issues that have happened that indicate the target is not translated:

- target is empty
- target is an exact match for the source
- target has a placeholder plus the actual source text like [ZH]ExactEnglishText

There are some exceptions:

- The unit header.application_name should never be translated and the target should match the source exactly.
  The customer, Minnesota Certification Board, decided they didn't want their name translated.

CHECK #12: Initial State
Checks if the the segment state is "initial" then the target element should either not exist or contain an exact copy of the source.

CHECK #13: XLIFF Placeholders
If a unit has an originalData element, then it uses XLIFF placeholders. These are pc and ph tags and they are used to escape 
makup (tags) so they do not get mangled during human or machine translation.

pc tag: is meant to enclose something with a <pc>asdfasdF</pc> but can be empty or even self-closed.
has a dataRefStart attribute which references a data element in the originalData element by id
has an optional dataRefEnd attribute which references a data element in the originalData element by id
The values of those data elements are the replacement values, the start pc tag is replaced by the value pointed 
to by dataRefStart, and the matching closing </pc> tag (careful, pc blocks can be nested) is replaced by the 
value in the data node with an id that matches the dataRefEnd.

ph tag: has a dataRef attribute which references a data element in the originalData element by id. The data element's value
represents what the <ph/> tag is repalced by.

This checks that the data element referenced by every dataRefStart, dataRefEnd, and dataRef exists.
It also checks to make sure every data element is referenced, and there are no unreferenced data elements.

If value of the source or target is HTML, then the pc tags represnt closeable elements like p, span, em, b, strong, etc 
and the ph tags represent self-closing elements like br, hr, img, etc.

If the data elements don't look like HTML tags, then the value is an Articulate Storyline or other type, and the tags represent 
something proprietary. Like with Storyline, it uses <Style> tags.

The actual value should be reconstructed using this process and validated.

If value is HTML (because the data elements had values that look like HTML tags) then the HTML fragment should be 
validated with an HTML 5 validator in its most strict mode (enabling all warnings).

Otherwise the value should be considered XML and an XML validator should be run on the XML fragment (enclosing it with a <root></root> first) 
in its most strict mode (enabling all warnings).

Each error or warning raised by the HTML or XML validator should generate a validation issue.

# XLIFF File Pair Validation Checks

These checks go beyond what a single file check can do and compare a language translation file against the English master, 
looking for issues in the translated file.

CHECK #14: Formatting
Validate the translated file has identical formatting to the English master, including leading/trailing whitespace and the first tag on the line matches.
This is the same as CHECK #9 above and calls the same utility method to perform the check, but instead of passing in source and target 
blocks as arrays of lines, this passes in the entire files as arrays of lines.

CHECK #15 Units
Check that the translated file has the same units as the English master. Each unit that is out of order, missing, or extra is a validation issue.

CHECK #16: XML Structure
Ensure that both files contain the exact same XML structure, matching tags, ordering, nesting, etc.
The easiest method may be to parse both files into an XML DOM and walk both trees in parallel comparing.

- Element nodes (name, attributes, attribute values) should always match with the exceptions noted below.
- Text nodes must match unless inside of a target element. When inside of a target element, no text node comparison is needed
  The exceptions:
1. the trgLang attribute on the xliff element
2. the value of the state attribute on a segment element
3. the text nodes inside of a value element
